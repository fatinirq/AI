{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatinirq/AI/blob/main/LSTMSpoiler_Updated_1_Dec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK59t6JTeC0b"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f46N2yhsqHrj"
      },
      "outputs": [],
      "source": [
        "#!pip install cloud-tpu-client==0.10 torch==1.12.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqQnQF1QXtig"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "#device = xm.xla_device()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhgLfZCye0-A",
        "outputId": "9190a2e1-80d2-4f6c-b28f-f3329363f010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4768,  0.5363],\n",
            "        [-0.7206, -0.6558],\n",
            "        [-0.5493, -0.9175]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Creates a linear module\n",
        "fc = torch.nn.Linear(5, 2, bias=True)\n",
        "\n",
        "# Copies the module to the XLA device (the first Cloud TPU core)\n",
        "fc = fc.to(device)\n",
        "\n",
        "# Creates a random feature tensor\n",
        "features = torch.randn(3, 5, device=device, requires_grad=True)\n",
        "\n",
        "# Runs and prints the module\n",
        "output = fc(features)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgiSThjSxtZ_"
      },
      "outputs": [],
      "source": [
        "pathData=\"/content/drive/My Drive/SpoilerData/GoodRead/\"\n",
        "pathResutlts=\"/content/drive/My Drive/SpoilerData/GoodRead/Results/\"\n",
        "pathModel=\"/content/drive/My Drive/SpoilerData/GoodRead/Model/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSnjotdfe8Is",
        "outputId": "e6b57fd4-1b2d-4046-c463-712922c79b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 104.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 81.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6ItHet7CEEW",
        "outputId": "6e36dad0-8a32-4747-bcbb-739a5589d697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.1482,  0.3221,  0.5559],\n",
              "        [-0.3872, -0.3388, -0.0269],\n",
              "        [ 0.1899, -0.2591,  0.0012],\n",
              "        [-0.1415,  0.5725, -0.1551],\n",
              "        [ 0.1234,  0.1026, -0.5254],\n",
              "        [-0.3078, -0.3254,  0.5738],\n",
              "        [-0.0058, -0.3624,  0.1766],\n",
              "        [ 0.0603, -0.3918, -0.2365],\n",
              "        [ 0.2572,  0.3192, -0.0309],\n",
              "        [ 0.5547, -0.1231,  0.2470],\n",
              "        [-0.3423, -0.0052,  0.3116],\n",
              "        [-0.2119,  0.1337, -0.3339]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "print(torch.__version__)\n",
        "lstm = nn.LSTM(3, 3)\n",
        "lstm.weight_ih_l0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7LLcRrd60Ab",
        "outputId": "50360907-2b17-459e-feb9-7e9d860a2320"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  6, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "a=torch.tensor([1,2,3])\n",
        "b=torch.tensor([1,3,5])\n",
        "c=a*b\n",
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpc3saAepPtz",
        "outputId": "53efbec3-fc10-4f1f-cc23-008a2e30a49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmIXW1SaiHH2"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "#import spacy\n",
        "import pandas as pd\n",
        "from torchtext import data\n",
        "#from torchtext.legacy.data import TabularDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from updatedRNN_model import RNN\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "#dataloader = DataLoader(iter(dfTrain['discourse_effectiveness',dfTrain['Preprocessed']), batch_size=8, shuffle=False, collate_fn=collate_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lBWDsnlg5Z-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/SpoilerData/intensity.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Zl5ji-iUYZ"
      },
      "outputs": [],
      "source": [
        "# df=df[:100000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqAEU9qMIBmw"
      },
      "outputs": [],
      "source": [
        "lst=df['topics'][0].replace(\"'\",'').replace(\"[\",'').replace(']','').split()\n",
        "lst2=[float(item) for item in lst]\n",
        "lst2.sort(reverse=True)\n",
        "#lst2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "Ne5vCSPQYCMw",
        "outputId": "e28f8bbe-985e-452c-9831-6e914edf7355"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unnamed: 0                                                       1136\n",
              "review_sentences                                                     \n",
              "user_id                              34216df2a5f3846b17e3f96bea6c2ad7\n",
              "timestamp                                                  2017-08-15\n",
              "rating                                                              3\n",
              "has_spoiler                                                     False\n",
              "book_id                                                       7818684\n",
              "review_id                            ee2b6a6ef25de1ddf311faedfee82357\n",
              "topics              [0.06873614 0.04656319 0.09090909 0.02439024 0...\n",
              "log                                                               0.0\n",
              "Name: 1136, dtype: object"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unnamed: 0                                                       1137\n",
              "review_sentences    love harry potter story course would like thin...\n",
              "user_id                              34216df2a5f3846b17e3f96bea6c2ad7\n",
              "timestamp                                                  2016-05-22\n",
              "rating                                                              5\n",
              "has_spoiler                                                     False\n",
              "book_id                                                      23734628\n",
              "review_id                            d82af813eb4698f492eb2c3f9be644fb\n",
              "topics              [0.10755149 0.0389016  0.09229596 0.00839054 0...\n",
              "log                                                       -887.747986\n",
              "Name: 1137, dtype: object"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "listind=[]\n",
        "count=0\n",
        "for ind in df.index:\n",
        "    if len(df['review_sentences'][ind].strip())==0:\n",
        "        listind.append(ind)\n",
        "\n",
        "display(df.iloc[listind[0]])\n",
        "if (len(listind)>0):\n",
        "  df.drop(listind, axis=0, inplace=True)\n",
        "display(df.iloc[listind[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_gCBiB1sshS",
        "outputId": "70e30646-b966-4dec-c7cd-1f221fa47816"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77878"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "_counter=0\n",
        "for ind in df.index:\n",
        "    if len(df['review_sentences'][ind].strip())>2000:\n",
        "        _counter+=1\n",
        "_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D05GFwpZfTlt",
        "outputId": "8edbe3c3-dac1-4dc3-e563-62643b963153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Unnamed: 0                                   review_sentences  \\\n",
              "0                 0  also high energy cosmic ray entering atmospher...   \n",
              "1                 1  avail free december http www audible com mt el...   \n",
              "2                 2  cheat system live choice learn daniela say lif...   \n",
              "3                 3  http www npr org recommended reading understan...   \n",
              "4                 4  surfer love end freya finding meaning surfing ...   \n",
              "...             ...                                                ...   \n",
              "1377686     1378028           travis abby travis abby wait travis pov    \n",
              "1377687     1378029           wait update finished read shelf forever    \n",
              "1377688     1378030  regardless april cannot come soon enough ok ma...   \n",
              "1377689     1378031  clockwork prince spell binding tale hooked sta...   \n",
              "1377690     1378032  promise worth perhaps thousand tomorrow never ...   \n",
              "\n",
              "                                  user_id   timestamp  rating  has_spoiler  \\\n",
              "0        8842281e1d1347389f2ab93d60773d4d  2017-08-30       5         True   \n",
              "1        8842281e1d1347389f2ab93d60773d4d  2017-03-22       3        False   \n",
              "2        8842281e1d1347389f2ab93d60773d4d  2017-03-20       3         True   \n",
              "3        8842281e1d1347389f2ab93d60773d4d  2016-11-09       0        False   \n",
              "4        8842281e1d1347389f2ab93d60773d4d  2016-04-25       4         True   \n",
              "...                                   ...         ...     ...          ...   \n",
              "1377686  35cef391b171b4fca45771e508028212  2013-04-16       0        False   \n",
              "1377687  35cef391b171b4fca45771e508028212  2012-12-28       0        False   \n",
              "1377688  35cef391b171b4fca45771e508028212  2013-03-25       4        False   \n",
              "1377689  35cef391b171b4fca45771e508028212  2013-01-24       4        False   \n",
              "1377690  35cef391b171b4fca45771e508028212  2012-12-29       5         True   \n",
              "\n",
              "          book_id                         review_id  \\\n",
              "0        18245960  dfdbb7b0eb5a7e4c26d59a937e2e5feb   \n",
              "1           16981  a5d2c3628987712d0e05c4f90798eb67   \n",
              "2        28684704  2ede853b14dc4583f96cf5d120af636f   \n",
              "3        27161156  ced5675e55cd9d38a524743f5c40996e   \n",
              "4        25884323  332732725863131279a8e345b63ac33e   \n",
              "...           ...                               ...   \n",
              "1377686  15745950  0e1db3d4b04256f9660f5d276ddf1314   \n",
              "1377687  10861195  0b7f352e58caf0fd1f961e98ef04e89c   \n",
              "1377688   6131164  9b19eff33ddb14e9e68fca2e90379e46   \n",
              "1377689  10025305  8be463fed78f0da63e964706f710332b   \n",
              "1377690   6482837  62ed1263c7d216986cc419cd4e8a408b   \n",
              "\n",
              "                                                    topics          log  \n",
              "0        [0.10335387 0.02806297 0.04859685 0.02806297 0... -1051.669067  \n",
              "1        [0.10335387 0.02806297 0.04859685 0.02806297 0...     0.000000  \n",
              "2        [0.05639308 0.09547739 0.02847571 0.03405918 0... -1197.603760  \n",
              "3        [0.18128654 0.00584795 0.00584795 0.00584795 0...  -202.208206  \n",
              "4        [0.07287295 0.03090424 0.06524228 0.03090424 0... -1810.500488  \n",
              "...                                                    ...          ...  \n",
              "1377686  [0.08183633 0.00199601 0.06187625 0.04191617 0...     0.000000  \n",
              "1377687  [0.08183633 0.00199601 0.06187625 0.04191617 0...     0.000000  \n",
              "1377688  [0.10224439 0.07730673 0.00249377 0.00249377 0...  -355.610931  \n",
              "1377689  [0.00126422 0.10240203 0.00126422 0.00126422 0...  -614.188171  \n",
              "1377690  [0.12240184 0.06301551 0.0465193  0.01022765 0... -1893.869263  \n",
              "\n",
              "[1377691 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2af6bb3-20d7-404d-add4-24ee74a72f96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review_sentences</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>rating</th>\n",
              "      <th>has_spoiler</th>\n",
              "      <th>book_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>topics</th>\n",
              "      <th>log</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>also high energy cosmic ray entering atmospher...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2017-08-30</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>18245960</td>\n",
              "      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n",
              "      <td>[0.10335387 0.02806297 0.04859685 0.02806297 0...</td>\n",
              "      <td>-1051.669067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>avail free december http www audible com mt el...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2017-03-22</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>16981</td>\n",
              "      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n",
              "      <td>[0.10335387 0.02806297 0.04859685 0.02806297 0...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>cheat system live choice learn daniela say lif...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2017-03-20</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>28684704</td>\n",
              "      <td>2ede853b14dc4583f96cf5d120af636f</td>\n",
              "      <td>[0.05639308 0.09547739 0.02847571 0.03405918 0...</td>\n",
              "      <td>-1197.603760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>http www npr org recommended reading understan...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2016-11-09</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>27161156</td>\n",
              "      <td>ced5675e55cd9d38a524743f5c40996e</td>\n",
              "      <td>[0.18128654 0.00584795 0.00584795 0.00584795 0...</td>\n",
              "      <td>-202.208206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>surfer love end freya finding meaning surfing ...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2016-04-25</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>25884323</td>\n",
              "      <td>332732725863131279a8e345b63ac33e</td>\n",
              "      <td>[0.07287295 0.03090424 0.06524228 0.03090424 0...</td>\n",
              "      <td>-1810.500488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377686</th>\n",
              "      <td>1378028</td>\n",
              "      <td>travis abby travis abby wait travis pov</td>\n",
              "      <td>35cef391b171b4fca45771e508028212</td>\n",
              "      <td>2013-04-16</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>15745950</td>\n",
              "      <td>0e1db3d4b04256f9660f5d276ddf1314</td>\n",
              "      <td>[0.08183633 0.00199601 0.06187625 0.04191617 0...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377687</th>\n",
              "      <td>1378029</td>\n",
              "      <td>wait update finished read shelf forever</td>\n",
              "      <td>35cef391b171b4fca45771e508028212</td>\n",
              "      <td>2012-12-28</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>10861195</td>\n",
              "      <td>0b7f352e58caf0fd1f961e98ef04e89c</td>\n",
              "      <td>[0.08183633 0.00199601 0.06187625 0.04191617 0...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377688</th>\n",
              "      <td>1378030</td>\n",
              "      <td>regardless april cannot come soon enough ok ma...</td>\n",
              "      <td>35cef391b171b4fca45771e508028212</td>\n",
              "      <td>2013-03-25</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>6131164</td>\n",
              "      <td>9b19eff33ddb14e9e68fca2e90379e46</td>\n",
              "      <td>[0.10224439 0.07730673 0.00249377 0.00249377 0...</td>\n",
              "      <td>-355.610931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377689</th>\n",
              "      <td>1378031</td>\n",
              "      <td>clockwork prince spell binding tale hooked sta...</td>\n",
              "      <td>35cef391b171b4fca45771e508028212</td>\n",
              "      <td>2013-01-24</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>10025305</td>\n",
              "      <td>8be463fed78f0da63e964706f710332b</td>\n",
              "      <td>[0.00126422 0.10240203 0.00126422 0.00126422 0...</td>\n",
              "      <td>-614.188171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377690</th>\n",
              "      <td>1378032</td>\n",
              "      <td>promise worth perhaps thousand tomorrow never ...</td>\n",
              "      <td>35cef391b171b4fca45771e508028212</td>\n",
              "      <td>2012-12-29</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>6482837</td>\n",
              "      <td>62ed1263c7d216986cc419cd4e8a408b</td>\n",
              "      <td>[0.12240184 0.06301551 0.0465193  0.01022765 0...</td>\n",
              "      <td>-1893.869263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1377691 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2af6bb3-20d7-404d-add4-24ee74a72f96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2af6bb3-20d7-404d-add4-24ee74a72f96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2af6bb3-20d7-404d-add4-24ee74a72f96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "jWSiEvPC63y9",
        "outputId": "38ace7db-2435-4477-e22c-9d0f62e8c0a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                   review_sentences  \\\n",
              "0           0  also high energy cosmic ray entering atmospher...   \n",
              "1           1  avail free december http www audible com mt el...   \n",
              "2           2  cheat system live choice learn daniela say lif...   \n",
              "3           3  http www npr org recommended reading understan...   \n",
              "4           4  surfer love end freya finding meaning surfing ...   \n",
              "\n",
              "                            user_id   timestamp  rating  has_spoiler  \\\n",
              "0  8842281e1d1347389f2ab93d60773d4d  2017-08-30       5         True   \n",
              "1  8842281e1d1347389f2ab93d60773d4d  2017-03-22       3        False   \n",
              "2  8842281e1d1347389f2ab93d60773d4d  2017-03-20       3         True   \n",
              "3  8842281e1d1347389f2ab93d60773d4d  2016-11-09       0        False   \n",
              "4  8842281e1d1347389f2ab93d60773d4d  2016-04-25       4         True   \n",
              "\n",
              "    book_id                         review_id  \\\n",
              "0  18245960  dfdbb7b0eb5a7e4c26d59a937e2e5feb   \n",
              "1     16981  a5d2c3628987712d0e05c4f90798eb67   \n",
              "2  28684704  2ede853b14dc4583f96cf5d120af636f   \n",
              "3  27161156  ced5675e55cd9d38a524743f5c40996e   \n",
              "4  25884323  332732725863131279a8e345b63ac33e   \n",
              "\n",
              "                                              topics          log  \n",
              "0  [0.10335387 0.02806297 0.04859685 0.02806297 0... -1051.669067  \n",
              "1  [0.10335387 0.02806297 0.04859685 0.02806297 0...     0.000000  \n",
              "2  [0.05639308 0.09547739 0.02847571 0.03405918 0... -1197.603760  \n",
              "3  [0.18128654 0.00584795 0.00584795 0.00584795 0...  -202.208206  \n",
              "4  [0.07287295 0.03090424 0.06524228 0.03090424 0... -1810.500488  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a4839cd-7b4b-41ed-a9dd-acd44874488c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review_sentences</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>rating</th>\n",
              "      <th>has_spoiler</th>\n",
              "      <th>book_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>topics</th>\n",
              "      <th>log</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>also high energy cosmic ray entering atmospher...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2017-08-30</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>18245960</td>\n",
              "      <td>dfdbb7b0eb5a7e4c26d59a937e2e5feb</td>\n",
              "      <td>[0.10335387 0.02806297 0.04859685 0.02806297 0...</td>\n",
              "      <td>-1051.669067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>avail free december http www audible com mt el...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2017-03-22</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>16981</td>\n",
              "      <td>a5d2c3628987712d0e05c4f90798eb67</td>\n",
              "      <td>[0.10335387 0.02806297 0.04859685 0.02806297 0...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>cheat system live choice learn daniela say lif...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2017-03-20</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>28684704</td>\n",
              "      <td>2ede853b14dc4583f96cf5d120af636f</td>\n",
              "      <td>[0.05639308 0.09547739 0.02847571 0.03405918 0...</td>\n",
              "      <td>-1197.603760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>http www npr org recommended reading understan...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2016-11-09</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>27161156</td>\n",
              "      <td>ced5675e55cd9d38a524743f5c40996e</td>\n",
              "      <td>[0.18128654 0.00584795 0.00584795 0.00584795 0...</td>\n",
              "      <td>-202.208206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>surfer love end freya finding meaning surfing ...</td>\n",
              "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
              "      <td>2016-04-25</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>25884323</td>\n",
              "      <td>332732725863131279a8e345b63ac33e</td>\n",
              "      <td>[0.07287295 0.03090424 0.06524228 0.03090424 0...</td>\n",
              "      <td>-1810.500488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a4839cd-7b4b-41ed-a9dd-acd44874488c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a4839cd-7b4b-41ed-a9dd-acd44874488c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a4839cd-7b4b-41ed-a9dd-acd44874488c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmUWKthSk2O_"
      },
      "outputs": [],
      "source": [
        "df.index=range(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tiXxmeYieQX"
      },
      "outputs": [],
      "source": [
        "z= [len(x) for x in list(df['review_sentences'])]\n",
        "z.sort(reverse=True)\n",
        "_max=max(z)\n",
        "_max=2000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x60BDi9ufpw8",
        "outputId": "294d34da-bbe9-42c1-8f97-1f8d6d6f6b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342\n"
          ]
        }
      ],
      "source": [
        "print(len(listind))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Zm9KJFH4FN"
      },
      "outputs": [],
      "source": [
        "lstParameter1=[]\n",
        "lstParameter2=[]\n",
        "for i in df.index:\n",
        "  lst=df['topics'][i].replace(\"'\",'').replace(\"[\",'').replace(']','').split()\n",
        "  lst2=[float(item) for item in lst]\n",
        "  lst2.sort(reverse=True)\n",
        "  lstParameter1.append(lst2[0])\n",
        "  lstParameter2.append(lst2[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L29IizZrj0d_"
      },
      "outputs": [],
      "source": [
        "df['param1']=lstParameter1\n",
        "df['param2']=lstParameter2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUnEOOI_hOOq",
        "outputId": "f91acd00-d0f6-4f83-99ee-1481fc2ef469"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "tokens = tokenizer(\"You can now install TorchText using pip!\")\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.loc[((df['param1']+df['param2']) >= 0.2) & (df['has_spoiler']==True) ]))\n",
        "print(len(df.loc[(df['has_spoiler']==True) ]))\n",
        "print(len(df.loc[((df['param1']+df['param2']) >= 0.5) & (df['has_spoiler']==False) ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JtGqa54K4ti",
        "outputId": "28ce9907-c23b-40b2-eb3a-3b960860c76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68940\n",
            "89627\n",
            "923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TP2nspdCVPf",
        "outputId": "a9accaa3-8a31-4f19-e9af-b76111d88d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:08<00:00, 48811.06it/s]\n"
          ]
        }
      ],
      "source": [
        "vec = torchtext.vocab.GloVe(name='6B', dim=50)\n",
        "#ret = vec.get_vecs_by_tokens(examples, lower_case_backup=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyyeJuBCW5l7"
      },
      "outputs": [],
      "source": [
        "# _max=2000\n",
        "# tokens=[tokenizer(item) for item in df['review_sentences']]\n",
        "# lengths=[len(token) for token in tokens]\n",
        "# vectors1=[vec.get_vecs_by_tokens(tokens[i][:_max], lower_case_backup=True) if lengths[i] > _max else vec.get_vecs_by_tokens(tokens[i]+['']*(_max-lengths[i]), lower_case_backup=True) for i in range(len(lengths))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOsbC_M0NeyO",
        "outputId": "1ff05785-b965-4b00-ecef-87a3fa24072e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1377691\n"
          ]
        }
      ],
      "source": [
        "print(len(lstParameter1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8o5CdhKiqeT",
        "outputId": "85721085-e3dd-4eb0-f675-9737965c569b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275539\n"
          ]
        }
      ],
      "source": [
        "trainData,testData=train_test_split(df,test_size=0.2)\n",
        "\n",
        "testData.reset_index(drop=True)#=range(len(testData))\n",
        "testData.index=range(len(testData))\n",
        "testData.head()\n",
        "print(len(testData))\n",
        "#del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "6pKFP3-f5pqE",
        "outputId": "4a054273-1604-40c6-a7ce-80a9ce16c318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Unnamed: 0                                   review_sentences  \\\n",
              "579216       579378  love love love author wonderful storytelling s...   \n",
              "220129       220224  vilma book blog facebook twitter review connec...   \n",
              "1358667     1359009  naturally given rise legendary fire hate heart...   \n",
              "1237676     1237989  stayed several hour late finish prop issue inc...   \n",
              "688259       688449  follow katniss peeta victory tour find despite...   \n",
              "\n",
              "                                  user_id   timestamp  rating  has_spoiler  \\\n",
              "579216   604f8693bfdcfdf6d01c3f5fd174f893  2016-11-17       5        False   \n",
              "220129   908b185d21d29d3dc12bbd414fee1ef2  2013-08-23       5        False   \n",
              "1358667  df063ed2b0cd3ee53ca1e11a6ebcdcd0  2017-07-26       1        False   \n",
              "1237676  063fa56483000312e88ea06c75cca06b  2017-07-27       4        False   \n",
              "688259   c71b6632fcedf35444a931e6f2a8a8f7  2011-10-02       4        False   \n",
              "\n",
              "          book_id                         review_id  \\\n",
              "579216   18001399  9d4f8848e639e8174a47ce3b7e99cd96   \n",
              "220129      83144  d446c500af79a5c8b033bac031d03a47   \n",
              "1358667    187181  dd1267b5f13b1d3658faf6babe39b12e   \n",
              "1237676  28449257  1f595c0f7033b4bce513b970d5a2ee55   \n",
              "688259    6148028  cf38fb2158a9d23681da2327e0284ade   \n",
              "\n",
              "                                                    topics          log  \\\n",
              "579216   [0.02439024 0.07084785 0.05923345 0.03600464 0...  -622.270996   \n",
              "220129   [0.04927418 0.03700675 0.04314046 0.02473932 0... -3041.244385   \n",
              "1358667  [0.11357341 0.08587258 0.05817175 0.03047092 0...  -318.057648   \n",
              "1237676  [0.08045977 0.04214559 0.04214559 0.00383142 0...  -265.565063   \n",
              "688259   [0.04564315 0.04564315 0.00414938 0.08713692 0...  -245.103424   \n",
              "\n",
              "           param1    param2  \n",
              "579216   0.082462  0.082462  \n",
              "220129   0.110611  0.065631  \n",
              "1358667  0.113573  0.085873  \n",
              "1237676  0.157088  0.080460  \n",
              "688259   0.170124  0.087137  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7958f054-b804-4126-b2cb-d4a233cc1cd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review_sentences</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>rating</th>\n",
              "      <th>has_spoiler</th>\n",
              "      <th>book_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>topics</th>\n",
              "      <th>log</th>\n",
              "      <th>param1</th>\n",
              "      <th>param2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>579216</th>\n",
              "      <td>579378</td>\n",
              "      <td>love love love author wonderful storytelling s...</td>\n",
              "      <td>604f8693bfdcfdf6d01c3f5fd174f893</td>\n",
              "      <td>2016-11-17</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>18001399</td>\n",
              "      <td>9d4f8848e639e8174a47ce3b7e99cd96</td>\n",
              "      <td>[0.02439024 0.07084785 0.05923345 0.03600464 0...</td>\n",
              "      <td>-622.270996</td>\n",
              "      <td>0.082462</td>\n",
              "      <td>0.082462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220129</th>\n",
              "      <td>220224</td>\n",
              "      <td>vilma book blog facebook twitter review connec...</td>\n",
              "      <td>908b185d21d29d3dc12bbd414fee1ef2</td>\n",
              "      <td>2013-08-23</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>83144</td>\n",
              "      <td>d446c500af79a5c8b033bac031d03a47</td>\n",
              "      <td>[0.04927418 0.03700675 0.04314046 0.02473932 0...</td>\n",
              "      <td>-3041.244385</td>\n",
              "      <td>0.110611</td>\n",
              "      <td>0.065631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358667</th>\n",
              "      <td>1359009</td>\n",
              "      <td>naturally given rise legendary fire hate heart...</td>\n",
              "      <td>df063ed2b0cd3ee53ca1e11a6ebcdcd0</td>\n",
              "      <td>2017-07-26</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>187181</td>\n",
              "      <td>dd1267b5f13b1d3658faf6babe39b12e</td>\n",
              "      <td>[0.11357341 0.08587258 0.05817175 0.03047092 0...</td>\n",
              "      <td>-318.057648</td>\n",
              "      <td>0.113573</td>\n",
              "      <td>0.085873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237676</th>\n",
              "      <td>1237989</td>\n",
              "      <td>stayed several hour late finish prop issue inc...</td>\n",
              "      <td>063fa56483000312e88ea06c75cca06b</td>\n",
              "      <td>2017-07-27</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>28449257</td>\n",
              "      <td>1f595c0f7033b4bce513b970d5a2ee55</td>\n",
              "      <td>[0.08045977 0.04214559 0.04214559 0.00383142 0...</td>\n",
              "      <td>-265.565063</td>\n",
              "      <td>0.157088</td>\n",
              "      <td>0.080460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688259</th>\n",
              "      <td>688449</td>\n",
              "      <td>follow katniss peeta victory tour find despite...</td>\n",
              "      <td>c71b6632fcedf35444a931e6f2a8a8f7</td>\n",
              "      <td>2011-10-02</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>6148028</td>\n",
              "      <td>cf38fb2158a9d23681da2327e0284ade</td>\n",
              "      <td>[0.04564315 0.04564315 0.00414938 0.08713692 0...</td>\n",
              "      <td>-245.103424</td>\n",
              "      <td>0.170124</td>\n",
              "      <td>0.087137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7958f054-b804-4126-b2cb-d4a233cc1cd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7958f054-b804-4126-b2cb-d4a233cc1cd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7958f054-b804-4126-b2cb-d4a233cc1cd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "trainData.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G403BaTVZLZO",
        "outputId": "d3ab8b32-f435-4a91-9d58-018f5272c75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220431\n"
          ]
        }
      ],
      "source": [
        "trainData,validData=train_test_split(trainData,test_size=0.2)\n",
        "\n",
        "trainData.reset_index(drop=True)#=range(len(trainData))\n",
        "trainData.index=range(len(trainData))\n",
        "validData.reset_index(drop=True)#=range(len(validData))\n",
        "validData.index=range(len(validData))\n",
        "\n",
        "print(len(validData))\n",
        "#del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "dLO5bPjC_0em",
        "outputId": "c06da465-cb40-4068-cf5c-49e65ed871de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                   review_sentences  \\\n",
              "0      898463  copy provided netgalley exchange honest review...   \n",
              "1       24784  good read always feel chest felt like expandin...   \n",
              "2     1098725  full review night owl review http www nightowl...   \n",
              "3      113928                      ago remember really enjoying    \n",
              "4      961276  also sobbing chapter ten heart enough felt lik...   \n",
              "\n",
              "                            user_id   timestamp  rating  has_spoiler  \\\n",
              "0  ed556b92506c3452b42fffed31697a1a  2015-07-19       5        False   \n",
              "1  1b44140d6d78f09468bd27e20925029c  2015-10-09       5        False   \n",
              "2  de8a5e808c457797cb1b357d8972e9d5  2016-06-11       3        False   \n",
              "3  d27de0320b0c8ebd47c811114afbef22  2014-03-26       3        False   \n",
              "4  716cfad9b0f39fa8e15b4a9f5961859b  2016-04-01       4        False   \n",
              "\n",
              "    book_id                         review_id  \\\n",
              "0  23355896  1dfa237c478565d1e55b0def520d999e   \n",
              "1   1162022  51e93ed1e89873605fe8e70a39415281   \n",
              "2    216363  e962f521f803539bb8e04dad6b02a1d5   \n",
              "3     47970  a851708ebe29b7524ce067dced941f8b   \n",
              "4     37435  5bbe691fe5e914c5bc02d3eea9ed98a5   \n",
              "\n",
              "                                              topics          log    param1  \\\n",
              "0  [0.08500973 0.04607398 0.05256327 0.01362751 0... -1050.955078  0.110967   \n",
              "1  [0.10747957 0.05091138 0.10747957 0.00691389 0... -1003.280518  0.132621   \n",
              "2  [0.02240326 0.08350305 0.08350305 0.00203666 0...  -400.378479  0.164969   \n",
              "3  [0.03870162 0.03870162 0.05118602 0.05118602 0...     0.000000  0.176030   \n",
              "4  [0.04146839 0.05506458 0.11624745 0.014276   0... -1059.143921  0.123046   \n",
              "\n",
              "     param2  \n",
              "0  0.104478  \n",
              "1  0.107480  \n",
              "2  0.144603  \n",
              "3  0.113608  \n",
              "4  0.116247  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b813749-fdc2-45b9-ad04-f46761c8349e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review_sentences</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>rating</th>\n",
              "      <th>has_spoiler</th>\n",
              "      <th>book_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>topics</th>\n",
              "      <th>log</th>\n",
              "      <th>param1</th>\n",
              "      <th>param2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>898463</td>\n",
              "      <td>copy provided netgalley exchange honest review...</td>\n",
              "      <td>ed556b92506c3452b42fffed31697a1a</td>\n",
              "      <td>2015-07-19</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>23355896</td>\n",
              "      <td>1dfa237c478565d1e55b0def520d999e</td>\n",
              "      <td>[0.08500973 0.04607398 0.05256327 0.01362751 0...</td>\n",
              "      <td>-1050.955078</td>\n",
              "      <td>0.110967</td>\n",
              "      <td>0.104478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24784</td>\n",
              "      <td>good read always feel chest felt like expandin...</td>\n",
              "      <td>1b44140d6d78f09468bd27e20925029c</td>\n",
              "      <td>2015-10-09</td>\n",
              "      <td>5</td>\n",
              "      <td>False</td>\n",
              "      <td>1162022</td>\n",
              "      <td>51e93ed1e89873605fe8e70a39415281</td>\n",
              "      <td>[0.10747957 0.05091138 0.10747957 0.00691389 0...</td>\n",
              "      <td>-1003.280518</td>\n",
              "      <td>0.132621</td>\n",
              "      <td>0.107480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1098725</td>\n",
              "      <td>full review night owl review http www nightowl...</td>\n",
              "      <td>de8a5e808c457797cb1b357d8972e9d5</td>\n",
              "      <td>2016-06-11</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>216363</td>\n",
              "      <td>e962f521f803539bb8e04dad6b02a1d5</td>\n",
              "      <td>[0.02240326 0.08350305 0.08350305 0.00203666 0...</td>\n",
              "      <td>-400.378479</td>\n",
              "      <td>0.164969</td>\n",
              "      <td>0.144603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>113928</td>\n",
              "      <td>ago remember really enjoying</td>\n",
              "      <td>d27de0320b0c8ebd47c811114afbef22</td>\n",
              "      <td>2014-03-26</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>47970</td>\n",
              "      <td>a851708ebe29b7524ce067dced941f8b</td>\n",
              "      <td>[0.03870162 0.03870162 0.05118602 0.05118602 0...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176030</td>\n",
              "      <td>0.113608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>961276</td>\n",
              "      <td>also sobbing chapter ten heart enough felt lik...</td>\n",
              "      <td>716cfad9b0f39fa8e15b4a9f5961859b</td>\n",
              "      <td>2016-04-01</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>37435</td>\n",
              "      <td>5bbe691fe5e914c5bc02d3eea9ed98a5</td>\n",
              "      <td>[0.04146839 0.05506458 0.11624745 0.014276   0...</td>\n",
              "      <td>-1059.143921</td>\n",
              "      <td>0.123046</td>\n",
              "      <td>0.116247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b813749-fdc2-45b9-ad04-f46761c8349e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b813749-fdc2-45b9-ad04-f46761c8349e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b813749-fdc2-45b9-ad04-f46761c8349e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "trainData.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZaiOPt61DPO",
        "outputId": "26cfacfc-e83c-4025-c98d-934f192f25ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11096691"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "trainData['param1'][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "boQydTI9r89P",
        "outputId": "d56aafa7-00eb-4c66-8cd6-20fb01b4a10d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ending completely took surprise writing style refreshing drawing reader without resorting overly simplistic style may common book type pleasantly surprised complexity plotline something come expect typical teenage paranormal series shadow kiss rose must choose priority test strength struggle balance deepening bond lissa intensifying series strigoi attack blossoming forbidden relationship dimitri trainer learn shadow kiss book rose also see spirit although character initially unsure whether functional gift symptom madness rose shadow kissed faced death healed spiritually bound lissa healer way embed friend feeling interaction make ideal protector lissa vampire moroi one good albeit weaker breed series center around heroine rose fated guard best friend lissa danger strigoi evil breed immortal vampire set kill destroy many teen novel found vampire diary series whim previously knowing anything character plotline story something admit frequently indulge world teenage book series rarely expect find hour frivolous fun soon forgotten '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "validData[\"review_sentences\"][1599]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un8JUtQAVktt"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.deterministic=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__H0XONS7PNT"
      },
      "outputs": [],
      "source": [
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, text, labels,param1,param2,_max):\n",
        "        self.labels = labels\n",
        "        self.text = text\n",
        "        self.max=_max\n",
        "        self.param1=torch.tensor(param1,dtype=torch.float32)\n",
        "        self.param2=torch.tensor(param2,dtype=torch.float32)\n",
        "        #self.param1=param1\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        label = self.labels[idx]\n",
        "        text = tokenizer(self.text[idx])\n",
        "        length=torch.tensor(len(text),dtype=torch.int64)\n",
        "        text= vec.get_vecs_by_tokens(text[:_max], lower_case_backup=True) if length > self.max else vec.get_vecs_by_tokens(text+['']*(self.max-length), lower_case_backup=True)\n",
        "        #print (length.shape)\n",
        "        param1=self.param1[idx]\n",
        "        param2=self.param2[idx]\n",
        "        #text=vec.get_vecs_by_tokens(text, lower_case_backup=True)\n",
        "        #print(text)\n",
        "        #idxTemp= tokenizer(self.text[idx], truncation=True)['input_ids']\n",
        "        #param1=self.param1\n",
        "        sample = {\"Text\": text, \"Class\": label,'Param1':param1,'Param2':param2,'Length':length}#,\"Vec\":vector}\n",
        "        return sample\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7VSfp7BAGqY"
      },
      "outputs": [],
      "source": [
        "label_pipeline = lambda x: torch.tensor(x,dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRpEeZnyq654"
      },
      "outputs": [],
      "source": [
        "batch_size=512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kCKMHAiA4Ci"
      },
      "outputs": [],
      "source": [
        "# def collate_batch(batch):\n",
        "#     _max=2000\n",
        "#     label_list, text_list, lengths = [], [], []\n",
        "#     text_tensor=torch.zeros([batch_size, _max,50], dtype=torch.float32)\n",
        "#     label_tensor=torch.zeros([batch_size], dtype=torch.float32)\n",
        "#     length_tensor= torch.zeros([batch_size], dtype=torch.int64)\n",
        "#     for idx,item in  enumerate(batch):\n",
        "\n",
        "#       _label=item['Class']\n",
        "#       _text=item['Text']\n",
        "\n",
        "#       label_list.append(label_pipeline(_label))\n",
        "#       _length=len(_text)\n",
        "#       if _length >_max:\n",
        "#         _text=_text[:_max]\n",
        "#         _length=_max\n",
        "#       else:\n",
        "#         _text=_text+['']*(_max-_length)\n",
        "#       processed_text =  vec.get_vecs_by_tokens(_text, lower_case_backup=True)\n",
        "#       #print(processed_text.shape)\n",
        "#       text_list.append(processed_text)\n",
        "\n",
        "#       text_tensor[idx]=processed_text\n",
        "#       #label_tensor[idx]=label_pipeline(_label)\n",
        "#       #length_tensor[idx]=_length\n",
        "#       lengths.append(_length)\n",
        "#     label_list = torch.tensor(label_list, dtype=torch.float32)\n",
        "#     #lengths = torch.tensor(lengths[:-1]).cumsum(dim=0)\n",
        "#     lengths = torch.tensor(lengths,dtype=torch.int64)\n",
        "#     text_list = torch.stack(text_list)\n",
        "\n",
        "#     return label_list.to(device), text_list.to(device), lengths.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3sAa5H5wxbf"
      },
      "outputs": [],
      "source": [
        "# def collate_batch2(batch):\n",
        "#     _max=2000\n",
        "#     label_list, text_list, lengths ,param1_list= [], [], [], []\n",
        "#     text_tensor=torch.zeros([batch_size, _max,50], dtype=torch.float32)\n",
        "#     label_tensor=torch.zeros([batch_size], dtype=torch.float32)\n",
        "#     length_tensor= torch.zeros([batch_size], dtype=torch.int64)\n",
        "#     for idx,item in  enumerate(batch):\n",
        "\n",
        "#       _label=item['Class']\n",
        "#       _text=item['Text']\n",
        "#       _param1=torch.tensor(item['Param1'])\n",
        "#       _param2=torch.tensor(item['Param2'])\n",
        "#       #print(idx,'param1',_param1.shape)\n",
        "\n",
        "#       label_list.append(label_pipeline(_label))\n",
        "#       _length=len(_text)\n",
        "#       if _length >_max:\n",
        "#         _text=_text[:_max]\n",
        "#         _length=_max\n",
        "#       else:\n",
        "#         _text=_text+['']*(_max-_length)\n",
        "#       processed_text =  vec.get_vecs_by_tokens(_text, lower_case_backup=True) * (_param1+_param2)\n",
        "#       #print(processed_text.shape)\n",
        "#       text_list.append(processed_text)\n",
        "#       #print(torch.tensor([item['Param1']+item['Param2']], dtype=torch.float32))\n",
        "#       text_tensor[idx]=processed_text.to(device)\n",
        "#       #label_tensor[idx]=label_pipeline(_label)\n",
        "#       #length_tensor[idx]=_length\n",
        "#       lengths.append(_length)\n",
        "#       param1_list.append(_param1)\n",
        "#     label_list = torch.tensor(label_list, dtype=torch.float32)\n",
        "#     #lengths = torch.tensor(lengths[:-1]).cumsum(dim=0)\n",
        "#     lengths = torch.tensor(lengths,dtype=torch.int64)\n",
        "#     text_list = torch.stack(text_list)\n",
        "#     #param1_list=torch.tensor(param1_list)\n",
        "#     return label_list.to(device), text_list.to(device), lengths.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mArAhQcKnkss"
      },
      "outputs": [],
      "source": [
        "def collate_batch3(batch):\n",
        "    _max=2000\n",
        "    #label_list, text_list, lengths ,param_list= [], [], [], []\n",
        "    #text_tensor=torch.zeros([batch_size, _max,50], dtype=torch.float32)\n",
        "    #label_tensor=torch.zeros([batch_size], dtype=torch.float32)\n",
        "    #length_tensor= torch.zeros([batch_size], dtype=torch.int64)\n",
        "    # embeddings = torch.stack([item['Text'][:_max]\n",
        "    #                           if item['Length'] > _max\n",
        "    #                           else vec.get_vecs_by_tokens(item['Text']+['']*(_max-item['Length']), lower_case_backup=True)\n",
        "    embeddings = torch.stack([item['Text']  for item in batch])\n",
        "    labels=torch.stack([label_pipeline(item['Class']) for item in batch])\n",
        "    params=torch.stack([(item['Param1'].clone().detach()+item['Param2'].clone().detach()) *2 for item in batch])\n",
        "    lengths= torch.stack([item['Length'] for item in batch])\n",
        "    return labels, embeddings,lengths,params\n",
        "    # for idx,item in  enumerate(batch):\n",
        "\n",
        "\n",
        "    #   _label=item['Class']\n",
        "    #   _text=item['Text']\n",
        "    #   _param1=item['Param1'].clone().detach().requires_grad_(True)\n",
        "    #   _param2=item['Param2'].clone().detach().requires_grad_(True)\n",
        "    #   #print(idx,'param1',_param1.shape)\n",
        "\n",
        "    #   label_list.append(label_pipeline(_label))\n",
        "    #   _length=len(_text)\n",
        "    #   if _length >_max:\n",
        "    #     _text=_text[:_max]\n",
        "    #     _length=_max\n",
        "    #   else:\n",
        "    #     _text=_text+['']*(_max-_length)\n",
        "    #   processed_text =  vec.get_vecs_by_tokens(_text, lower_case_backup=True)\n",
        "    #   #print(processed_text.shape)\n",
        "    #   text_list.append(processed_text)\n",
        "    #   param_list.append(_param1+_param2)\n",
        "    #   #print(torch.tensor([item['Param1']+item['Param2']], dtype=torch.float32))\n",
        "    #   #text_tensor[idx]=processed_text.to(device)\n",
        "    #   #label_tensor[idx]=label_pipeline(_label)\n",
        "    #   #length_tensor[idx]=_length\n",
        "    #   lengths.append(_length)\n",
        "    # label_list = torch.tensor(label_list, dtype=torch.float32)\n",
        "    # #lengths = torch.tensor(lengths[:-1]).cumsum(dim=0)\n",
        "    # lengths = torch.tensor(lengths,dtype=torch.int64)\n",
        "    # text_list = torch.stack(text_list)\n",
        "    # param_list=torch.tensor(param_list,dtype=torch.float32)\n",
        "    # return label_list, text_list, lengths,param_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWqgADGY9MRR"
      },
      "outputs": [],
      "source": [
        "# define data and class labels\n",
        "##text = ['Happy', 'Amazing', 'Sad', 'Unhapy', 'Glum']\n",
        "##labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
        "# create Pandas DataFrame\n",
        "##text_labels_df = pd.DataFrame({'Text': text, 'Labels': labels})\n",
        "# define data set object\n",
        "_max=2000\n",
        "\n",
        "TD = CustomTextDataset(trainData['review_sentences'],trainData['has_spoiler'],trainData['param1'],trainData['param2'],_max)\n",
        "TTD=CustomTextDataset(testData['review_sentences'],testData['has_spoiler'],testData['param1'],testData['param2'],_max)\n",
        "VD=CustomTextDataset(validData['review_sentences'],validData['has_spoiler'],validData['param1'],validData['param2'],_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz2Fg3j7Zg-j"
      },
      "outputs": [],
      "source": [
        "# trainIter = DataLoader(TD, batch_size=batch_size, shuffle=True,collate_fn=collate_batch)\n",
        "# testIter = DataLoader(TTD, batch_size=batch_size, shuffle=True,collate_fn=collate_batch)\n",
        "# validIter = DataLoader(VD, batch_size=batch_size, shuffle=True,collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7_12_66xRIw"
      },
      "outputs": [],
      "source": [
        "# trainIter2 = DataLoader(TD, batch_size=batch_size, shuffle=True,collate_fn=collate_batch2)\n",
        "# testIter2 = DataLoader(TTD, batch_size=batch_size, shuffle=True,collate_fn=collate_batch2)\n",
        "# validIter2 = DataLoader(VD, batch_size=batch_size, shuffle=True,collate_fn=collate_batch2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv0nrdQX8PEJ",
        "outputId": "fbe1e706-29cd-4086-b6f7-b3a39c04eee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0643, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(torch.tensor(df['param2'][3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XmtYyI2oc2H"
      },
      "outputs": [],
      "source": [
        "trainIter3 = DataLoader(TD, batch_size=batch_size,collate_fn=collate_batch3,num_workers=4,prefetch_factor=8,pin_memory=True,shuffle=True)\n",
        "testIter3 = DataLoader(TTD, batch_size=batch_size,collate_fn=collate_batch3,num_workers=4,prefetch_factor=8,pin_memory=True,shuffle=True)\n",
        "validIter3 = DataLoader(VD, batch_size=batch_size,collate_fn=collate_batch3,num_workers=4,prefetch_factor=8,pin_memory=True,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL7TaEoED952",
        "outputId": "dae09e1d-f845-4a87-ec98-4a014c801f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "______________\n",
            "Label= torch.Size([512])\n",
            "Text= torch.Size([512, 2000, 50])\n",
            "offsets= tensor([108,  24, 129,   8,  22,  16,  57, 157, 218,  73,  57,  30, 190,  67,\n",
            "        106, 231,  36, 202, 138, 635,   9,  27,   6,  66, 384, 112, 240, 183,\n",
            "         30,  29,   4, 192, 183,  18,  11,   9,  12,  23,  41, 331, 215, 101,\n",
            "          4, 294, 301,  28, 273,  17, 220, 379,  22,  70,   7,   2, 298,  72,\n",
            "          8,  17, 144, 278,  45,  20,  12,  21,  27, 131,  12,  13,   7,  65,\n",
            "          3,  30,  33,  11,   5, 130,  64, 100,  69,  72,  86,  28,  25,   7,\n",
            "         45,  13,   4,  20,  84,  71,  15,  95,   8,  58, 124, 294,  45, 250,\n",
            "        154, 117, 270, 126,  16,  19,   2,   5,   4,  82,   2,  34,  94,   8,\n",
            "         44, 136, 403,  64, 163,  38,   7,  32,   5, 204,  83, 572,  84, 350,\n",
            "         96,  55,  36,  54,  68, 179, 152, 141,  66, 135,  88, 328, 365,  34,\n",
            "         79, 158,  39, 100, 102, 267, 247,  10,  57,  16, 252,   6,  55,  95,\n",
            "         71,  51,  86,  42, 185, 491, 105, 158,  75,   3, 336, 114,  23,   8,\n",
            "          3,  54, 139,   2,  12,  48,  24, 133,   6,   3,  50, 119,  12,  22,\n",
            "        321,  56, 102,  83,  10,  36,  34,  55,  13,  73, 436, 250,  48,  19,\n",
            "         60, 112,  55,  13,  13,   5,  50,  56,  29, 157,  51, 272, 268, 188,\n",
            "          7,  54, 177,  41, 155, 304, 172,  23, 122,  76,  32, 124,  13,  15,\n",
            "          9,  23,   8,  62,   4, 193,  26,  36,  14, 146,  93, 109,  84,  33,\n",
            "        238,   2, 337,  11,  93,  27, 166, 441, 294, 114,   5,  13, 146,  76,\n",
            "         42, 419, 155,  40,  10,  70,  31, 100,  17,  83,  80,   9, 162,  96,\n",
            "         36, 107,  14, 418,  11,  47,  82, 148, 100, 120,   3, 157, 651,  15,\n",
            "        112, 169,   9,  25,  88, 372, 294, 138,  30,  56,  42, 140, 345,  39,\n",
            "         30,  56, 192, 225, 450,   7,  28,  15, 105, 235,  49, 249, 786,  40,\n",
            "         23, 185, 250, 200, 214, 359,  38,  25,  38, 133,   9,   7,  20, 101,\n",
            "         73,  43,  46, 238,  12,  75, 132,  23,  30,  71,  42,  20,  67, 132,\n",
            "        176, 147, 208,  34,  10,  44,   8, 133,  56,  10, 285,  11,   2, 274,\n",
            "         46,  35,  94,  13, 336, 235,  47,  19,  77,   7,  90,  57,  23,   2,\n",
            "         35, 176,  67, 633,  47,   5,  68, 140,  30, 295, 168,  65,  16,  17,\n",
            "         30,   7,  42,  40,  23, 162,  26,  26,  63, 362,   8,  17, 159,  34,\n",
            "          6,   9,  40, 164,  55,  35,  54, 345, 121,  74,  12,  59,  49,  33,\n",
            "         79, 130, 222,  85,  92, 154, 252,  64,  58,  93,  38,   5,   2,  20,\n",
            "         14, 180, 180,  12,  49, 374,  85,  38,   3,   3,   7,  15,  76,  32,\n",
            "        131,  35, 224,   8,   4, 163,  53,  16, 126,   3, 115, 179, 106,   3,\n",
            "        313, 195, 117,  23,  11, 184,  47,  38,  88, 309, 138,  44,  54,  29,\n",
            "        145,  20,   2, 131,  15, 126, 106, 165,  80,  22,  66, 165,  25,  79,\n",
            "        115, 223, 447,  22,  22, 109, 129,  43,  89,  71, 391,  17,   5, 108,\n",
            "         59,  74,   5,  32, 106, 346, 117,  20,  55, 455,  25,  93,  34, 122,\n",
            "         46, 266, 192, 125,  22,  93,   6, 129])\n",
            "params= torch.Size([512])\n",
            "1\n",
            "______________\n",
            "Label= torch.Size([512])\n",
            "Text= torch.Size([512, 2000, 50])\n",
            "offsets= tensor([401, 317,  57, 184, 104,  85,  59,  28, 240,  12,   3,  61,  62,   9,\n",
            "         15, 125, 101,  69,  71,  70, 183,  46,  26,   5, 263,  30,   9,  18,\n",
            "         17,  68,  50, 372,   7,   2,  40,  31, 174,  96,  65,  55,  32,   5,\n",
            "         33,  99,  52, 233,  13,  13,  90,   2,   6, 183,  90,  21, 198,  24,\n",
            "         16,  40,  22,  18, 392, 140,  15,  56, 299,  48,   4,  16,  33,  54,\n",
            "        155, 176,  77,  16, 366, 107, 210,  49,   3,  23, 547, 112,  61, 176,\n",
            "         56, 125,  18,  64,   9,   9,   5, 112,   4,   8,  68,  27,  18, 146,\n",
            "         87,  42, 182, 164,  44,  50,   3, 292,  35, 185,   9, 280,  13,  97,\n",
            "         33,  17,  94,  26,   4,  39, 138,   3,   3,  27,  61,  15,  28,   3,\n",
            "         68,  60, 168,   3, 177,   4, 219,   8,  10,  41, 174,  34,  41,  89,\n",
            "        176, 143,   4,  90,  23,  34,  15,  51,  17, 125,  11,  73,  57, 279,\n",
            "         33, 179,  12,  21, 243,  73,  13, 151, 163,  39,  36, 173,  24, 244,\n",
            "        160, 201,   5,   7, 226, 148,  35, 154,  94,   2,  62,  15,  54,  31,\n",
            "         11, 115,  22, 109, 198, 549,  24,  82,  11,  20,  67,  18, 260, 115,\n",
            "        181,  81,  56,  15,  20,  90,  56,  43,  80,  96, 217, 153,  48,  26,\n",
            "         67,   9, 208,   5,  90, 331, 270,  23,  17,  23,  29,  67,  19, 197,\n",
            "         83, 131, 329,  92, 114, 292, 141, 122, 552,  82,  32, 308,  32, 587,\n",
            "         75,  65,  29,  47,  24,  27,  80,  42,  44,  63,  89,  54,  31, 215,\n",
            "         43,  36,  16,  50,  22,   2,  67,  42,  68,  88,   3,  38, 154,  99,\n",
            "          3,  15,  29,  32,   5,  12,  47,  80,  70,  29,  50, 274, 136,   3,\n",
            "        104,  14,  84,   6,  79, 152,   1,  58,  45,   2,  14, 274,  19,  12,\n",
            "         46, 258, 155,   7,  16,  21,  46,  51, 163, 400,   9, 120, 151,  93,\n",
            "         20, 199,   1,  85,  52,  62, 240, 156,  23,  36,   6,  38,  74,  21,\n",
            "         46,  61,  65, 235,  10,   5,  50,  58, 146,  54,  38, 116, 318,  36,\n",
            "         31, 344,  24, 100, 125,  25, 292,  46,   8,   3,   5,  23, 115,  31,\n",
            "        134,  26,  15,  22,   5,   4,  36, 162,  35, 305,  11,  17,  61,  15,\n",
            "         26, 450, 224, 322,   9,  75, 180,  46,   3,  22,  87,  14,  84, 128,\n",
            "         59,  27,  42,  47,  92,  86,  58, 309, 300, 310, 241, 236, 123,  33,\n",
            "         40,  11, 125,  21,  25,  12,  75,  51,  87,  10,   2, 406, 107,   1,\n",
            "        324,  90, 150,  65, 354,   7,   6,  76,  10,  36,   6,   5,  73, 267,\n",
            "         44,  12,  73,  21,  27, 389,   5,  51, 110, 117,   8,   4,   4,  19,\n",
            "         48, 273,  16,  45, 335,  28,   2,  71,   2, 155,  12, 134,  24,  32,\n",
            "        138, 407, 273,  71,  99, 153,  43,  25,  21,  15, 180, 237, 194,  60,\n",
            "         14,  51,  16, 262,  17,   6,  67, 777,  90,  51,  64,  80,  47,  29,\n",
            "         27, 180,  21,  13, 324,  59,  31,   6, 106,  22,   4,  53,   7, 127,\n",
            "        154, 202, 102,  70, 102,   1,  82,  34, 242,  41,   7,  64,  35,  77,\n",
            "         44, 140,  74, 194,  99,  22,  27,  41])\n",
            "params= torch.Size([512])\n",
            "2\n",
            "______________\n",
            "Label= torch.Size([512])\n",
            "Text= torch.Size([512, 2000, 50])\n",
            "offsets= tensor([ 24, 108,  11, 226, 148, 138, 231,   3,  14,  23,   1,  10, 157, 291,\n",
            "        100,  66, 196,  16, 218,  86,   6,  12,  60,  25, 121,  25,  26,  37,\n",
            "         71, 141, 342, 190,  77,  98,   4,  18,  33,  45,  38,  15,  34,  14,\n",
            "          8,  40,  12,  13,  33,  14,  23, 112,  82,   2, 471,  30,  19,  31,\n",
            "         23, 212,  65,  89,  84, 177, 130,  17,   6,  36,  17,  77,  84,  39,\n",
            "         78,  18,  35,  41,  12, 562,   6,  75,  65, 464,  28,  88, 109,  21,\n",
            "          9,  23,  42, 145,   2,  57,  54, 139,  45,  46,  23,  38,  16,   4,\n",
            "         36,  53,  43,  79,  11,  27,  18, 228, 343, 150,  45,  78,  42,  14,\n",
            "        273,  11, 152, 136, 161,  68,  42, 617, 413, 511, 562, 148,  28,  35,\n",
            "         90, 112,  21,  25,  29,  27,  31, 113,   8,  25,  26,  16,  18,   3,\n",
            "         11,  22,   7, 255,  57,  83,  93, 655,  33, 121,  42, 217,  11,   2,\n",
            "         66,  13, 261,  30,   9,  40,   6, 161, 152,  81,  16,  10,  14,  78,\n",
            "         14, 245,  24, 110, 201,  26,  43,  38,  36,  25,   2,  47,  50,  84,\n",
            "        153,  21,  85, 401,  96,  58,  22,   6,  80,   6,  15,  12,  88, 301,\n",
            "         34, 289,  13, 189,  16,  12,   3, 101,  32,  10, 138,   6, 418,  83,\n",
            "         10, 297,  18,  25,  41, 510, 173, 316, 176,  67, 335, 200,  13,  48,\n",
            "         64, 165, 187,  68, 108,  10, 130, 635,   3, 280, 200,  23, 160,  75,\n",
            "          5, 429,   9, 118, 294,  39,  69,   5,  86,  12,   4,  22,   6,  38,\n",
            "         16,  90,  49, 398,  21, 133,  56,  34,   8,  24,  65,  42,  27,  62,\n",
            "          9, 164, 177,  18, 114,  25,  89, 187,  11, 299, 140,  80,  27,   8,\n",
            "        328, 202,  11,  12, 219,  36,  75, 219,  81,  30, 143,  11,  43,  10,\n",
            "         55, 286,  53,  32,  10,  64,  38,  45,  38,  33,  14,  80,  44,  13,\n",
            "          2,  14,  23,   7, 173,   5,  61,  23,  58,  31, 163, 120, 204,  38,\n",
            "         48, 272,  10,  30,  39,  36,  85,  11,  16,  22,  70,  56,   9,  79,\n",
            "         85, 122,   6,   7, 155,  80, 200,  20, 238, 183, 124,   3, 308, 235,\n",
            "         18,  17,  22,  22, 172,  22,  11,  27,  37,   9,   9, 618, 169, 104,\n",
            "         27,  14, 302,   9, 161,  16,  10,   9,  62,  27,   7,  57,  30, 159,\n",
            "        282,   2,  31, 350,   5,  69, 129,  73,   5,  41,  43,  27, 117,  64,\n",
            "         46,  20,  69,  11,  40, 120,  60, 268,   6,  66,   6, 530, 265,  19,\n",
            "        102,  66,  35, 305, 204,  27,  10,  62, 390,  12,   6, 147,  11,  33,\n",
            "         10,   3,   7,  76,  56,  17,  52, 124,  26,  87, 229, 164,  96,   4,\n",
            "         17,  32, 115,  10,  31,  60,  41, 441,  20,  13,  10,  67,   4, 321,\n",
            "        137,  18, 207, 152,  34, 145,  13, 101,   7, 117,  12, 567, 134, 140,\n",
            "         20, 153,  38, 253,  66,  71, 277,  10,  54,  95,  32,  15,  69,  38,\n",
            "         35,  11,  73,  93, 269, 224,  92,  58,   5,  19,  45,  95,  71,  21,\n",
            "        239,  92,  33, 183, 121,  48,  18, 261,   2, 256,   2,  27,  13,  44,\n",
            "        349, 120,  16,  44,   3,  98, 158,   8])\n",
            "params= torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "# for idx, batch in enumerate(TD):\n",
        "#   print(batch['Class'])\n",
        "#   if idx>2:\n",
        "#     break\n",
        "for idx, (label, text,lengths,params) in enumerate(trainIter3):\n",
        "    # Print the 'text' data of the batch\n",
        "    print(idx)\n",
        "    print(\"______________\")\n",
        "    print(\"Label=\",label.shape)\n",
        "    print(\"Text=\",text.shape)\n",
        "    print(\"offsets=\",lengths)\n",
        "    print(\"params=\",params.shape)\n",
        "    if idx>1:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "IbiE6mi7-L8S",
        "outputId": "bb120206-aaf1-4ebd-bab5-1f6620f85532"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grade c nice action fright mention least page long thing character narrative thrust fun stephen king took realistic situation superflu wiping world put supernatural force top despite derivative stephen king classic stand take element make masterpiece ugh transform bat collective mind oh yeah also supernatural little girl talk via telepathy human animal hope super strength stand light thirst human blood live forever something like vampire actual vampire within first page suppose accept supervirus creating vampire passage suspend disbelief review game throne willing accept fictional world kingdom mysterious zombie northern land fiction tricky '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "trainData['review_sentences'][1136]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6_GBJDMst9a",
        "outputId": "7289897d-0156-4187-8ae4-a420242ce890"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import gc\n",
        "gc.enable()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEPJSiytoqky"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional,\n",
        "                 dropout_rate,pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim,sparse=True,padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional,\n",
        "                            dropout=dropout_rate, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        # ids = [batch size, seq len]\n",
        "        # length = [batch size]\n",
        "        #rint(text.shape)\n",
        "        #embedded = self.embedding(text)\n",
        "        # embedded = [batch size, seq len, embedding dim]\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(text, offsets.type(torch.int64).cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        # output = [batch size, seq len, hidden dim * n directions]\n",
        "        if self.lstm.bidirectional:\n",
        "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
        "            # hidden = [batch size, hidden dim * 2]\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1])\n",
        "            # hidden = [batch size, hidden dim]\n",
        "        prediction = self.fc(hidden)\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6atRI0Pko_vF"
      },
      "outputs": [],
      "source": [
        "class LSTM3(nn.Module):\n",
        "    def __init__(self,  features_dim, hidden_dim, output_dim, n_layers, bidirectional,\n",
        "                 dropout_rate):\n",
        "        super().__init__()\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim,sparse=True,padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(features_dim, hidden_dim, n_layers, bidirectional=bidirectional,\n",
        "                            dropout=dropout_rate, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.fc2 = nn.Linear(output_dim+1, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, text, offsets,param):\n",
        "        # ids = [batch size, seq len]\n",
        "        # length = [batch size]\n",
        "        #rint(text.shape)\n",
        "        #embedded = self.embedding(text)\n",
        "        # embedded = [batch size, seq len, embedding dim]\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(text, offsets.type(torch.int64).cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # cell = [n layers * n directions, batch size, hidden dim]\n",
        "        output, output_length = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        # output = [batch size, seq len, hidden dim * n directions]\n",
        "        if self.lstm.bidirectional:\n",
        "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
        "            # hidden = [batch size, hidden dim * 2]\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1])\n",
        "            # hidden = [batch size, hidden dim]\n",
        "        temPrediction = self.fc1(hidden)\n",
        "        #print(param.get_device())\n",
        "        #print(temPrediction.get_device())\n",
        "        prediction=self.fc2(torch.stack((param,temPrediction.squeeze()),dim=-1))\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy8dIcb9TB0h"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import GloVe, vocab\n",
        "unk_token = \"pad\"\n",
        "pad_token=\"unk\"\n",
        "\n",
        "glove_vectors = vec\n",
        "glove_vocab = vocab(glove_vectors.stoi)\n",
        "unk_index = glove_vectors.stoi[unk_token]\n",
        "\n",
        "#this is necessary otherwise it will throw runtime error if OOV token is queried\n",
        "glove_vocab.set_default_index(unk_index)\n",
        "pretrained_embeddings = glove_vectors.vectors\n",
        "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))\n",
        "UNK_IDX = glove_vectors.stoi[unk_token]\n",
        "PAD_IDX = glove_vectors.stoi[pad_token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgVig-vdlV0s",
        "outputId": "7cdd34ee-b7ca-47db-830d-d83c3a5a1c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n"
          ]
        }
      ],
      "source": [
        "INPUT_DIM = len(glove_vectors.vectors)\n",
        "print(INPUT_DIM)\n",
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 1\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = glove_vectors.stoi[pad_token]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxra9y-UqypK",
        "outputId": "4548dfbf-bb2e-46d1-aee0-b1ca1af33388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (embedding): Embedding(400000, 50, padding_idx=201534, sparse=True)\n",
            "  (lstm): LSTM(50, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "LSTM3(\n",
            "  (lstm): LSTM(50, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc1): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "model = LSTM(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL,\n",
        "            DROPOUT,PAD_IDX)\n",
        "print(model)\n",
        "\n",
        "\n",
        "model3 = LSTM3(\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL,\n",
        "            DROPOUT)\n",
        "print(model3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2acJ6RSiAHhy",
        "outputId": "a31f695d-ebcf-48ef-d4bb-4ff60794308f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.0184, -0.5705, -1.6740,  ..., -0.2228,  0.8013, -1.0592],\n",
            "        [ 1.4134, -0.1229,  1.0986,  ..., -0.0856, -1.2477,  0.1680],\n",
            "        [ 1.2120,  0.3198, -0.7829,  ..., -0.3074,  0.5359,  0.1375],\n",
            "        ...,\n",
            "        [ 1.9423,  0.7974,  0.7858,  ...,  2.2333, -0.2870,  0.8297],\n",
            "        [-0.8613, -1.3938,  0.5874,  ...,  1.2875,  0.0369,  1.9340],\n",
            "        [-0.4313,  0.2161,  0.0671,  ...,  1.2551,  1.2085, -0.2148]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "print(model.embedding.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QJkCSYc2SHp"
      },
      "outputs": [],
      "source": [
        "# model3.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "# model3.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "# print(model3.embedding.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WML-RnQyGKLF",
        "outputId": "56e83cc5-d355-41ae-e663-df728e060e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-model-summary\n",
            "  Downloading pytorch_model_summary-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-model-summary) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch-model-summary) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pytorch-model-summary) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pytorch-model-summary) (4.1.1)\n",
            "Installing collected packages: pytorch-model-summary\n",
            "Successfully installed pytorch-model-summary-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-model-summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTS1rfx8lb1q"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmNHgejvlgVj",
        "outputId": "432864ec-0c09-4801-9250-59269d37f6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 20,121,801 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3BGXEn-2cbO",
        "outputId": "5ccec43f-1ddc-40fa-fc4a-b7173ccff4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 121,804 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "print(f'The model has {count_parameters(model3):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4AFIykBMK07",
        "outputId": "05ef8062-6f53-44df-d59b-212cdfd55c34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWXRpgyPlt7y",
        "outputId": "8a5a0d79-34e5-4c2c-934c-9a7542c32726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "print(torch.__version__)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "optimizer3=optim.Adam(model3.parameters())\n",
        "\n",
        "criterion =nn.BCEWithLogitsLoss()\n",
        "\n",
        "criterion = criterion.to(device)\n",
        "model = model.to(device)\n",
        "model3=model3.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWPrtXjLVLvV",
        "outputId": "bc2b99ef-7ade-4c61-c1cd-0c791ab01bc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "y = np.array([1, 1, 2, 2])\n",
        "pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n",
        "metrics.auc(fpr, tpr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48yflBjYhLET"
      },
      "outputs": [],
      "source": [
        "def focal_loss(bce_loss, targets, gamma, alpha):\n",
        "    \"\"\"Binary focal loss, mean.\n",
        "\n",
        "    Per https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/5 with\n",
        "    improvements for alpha.\n",
        "    :param bce_loss: Binary Cross Entropy loss, a torch tensor.\n",
        "    :param targets: a torch tensor containing the ground truth, 0s and 1s.\n",
        "    :param gamma: focal loss power parameter, a float scalar.\n",
        "    :param alpha: weight of the class indicated by 1, a float scalar.\n",
        "    \"\"\"\n",
        "    p_t = torch.exp(-bce_loss)\n",
        "    alpha_tensor = (1 - alpha) + targets * (2 * alpha - 1)  # alpha if target = 1 and 1 - alpha if target = 0\n",
        "    f_loss = alpha_tensor * (1 - p_t) ** gamma * bce_loss\n",
        "    return f_loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9zH5GbOl5Gm"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(rounded_preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "\n",
        "    correct = (rounded_preds == y).float() #convert into float for division\n",
        "    acc = correct.sum() / len(rounded_preds)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIh0oEbPmFN9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvoQO0ojUA0r",
        "outputId": "dfc6aafc-aa3a-424c-cbe3-331e33c26e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlajLpprl6Be"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "from torchmetrics.classification import PrecisionRecallCurve\n",
        "#from torchmetrics import AUC\n",
        "\n",
        "\n",
        "\n",
        "# initialize metric\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    #aucMetric =0 # AUC(compute_on_step=True,reorder=True)\n",
        "    F1Metric=torchmetrics.F1Score(task='binary',compute_on_step=True).cuda()\n",
        "\n",
        "    PrecMetric=torchmetrics.Precision(task='binary',compute_on_step=True).cuda()\n",
        "    RecallMetric=torchmetrics.Recall(task='binary',compute_on_step=True).cuda()\n",
        "    aucRCurveMetric=torchmetrics.AUROC(task='binary',compute_on_step=True).cuda()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_auc=0\n",
        "    TP_train,TN_train,FP_train,FN_train=0,0,0,0\n",
        "    model.train()\n",
        "    gamma = torch.tensor(1.0, dtype = torch.float32).cuda()\n",
        "    alpha=torch.tensor(0.9, dtype = torch.float32).cuda()\n",
        "    for idx, (label, text, offsets) in enumerate(iterator):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #print(batch)\n",
        "        #print(batch.data)\n",
        "\n",
        "        predictions=model(text,offsets).squeeze(1)\n",
        "\n",
        "        predictionsigmoid=torch.sigmoid(predictions)\n",
        "        rounded_preds=torch.round(predictionsigmoid)\n",
        "        #if idx==0:\n",
        "        #  print('predictions',predictionsigmoid)\n",
        "\n",
        "        #print(rounded_preds)\n",
        "\n",
        "        #print(\"Batch labels  \"+ batch.label.int().cuda())\n",
        "        bce_loss = criterion(predictions, label)\n",
        "        loss= focal_loss(bce_loss,label,gamma,alpha)\n",
        "        #print(loss)\n",
        "\n",
        "        acc = binary_accuracy(rounded_preds, label)\n",
        "        #aucMetric.update(rounded_preds, label)\n",
        "        F1Metric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "        PrecMetric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "        RecallMetric.update(rounded_preds,label.type(torch.IntTensor).cuda())\n",
        "        aucRCurveMetric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "        for i in range(len(label)):\n",
        "          if label[i]==0 and rounded_preds[i]==0:\n",
        "            TN_train+=1\n",
        "           # print (TN_train)\n",
        "          elif label[i]==1 and rounded_preds[i]==1:\n",
        "            TP_train+=1\n",
        "          elif label[i]==1 and rounded_preds[i]==0:\n",
        "            FP_train+=1\n",
        "          elif label[i]==0 and rounded_preds[i]==1:\n",
        "            FN_train+=1\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    allMetrics={'AUC':0,'Precision':PrecMetric.compute(),'Recall':RecallMetric.compute(),\n",
        "                'F1':F1Metric.compute(),'AUCR':aucRCurveMetric.compute()}\n",
        "\n",
        "    #allMetrics={'AUC':aucMetric.compute(),'F1':F1Metric.compute(),'Precision':PrecMetric.compute(),\n",
        "    #            'Recall':RecallMetric.compute(),'AUCR':aucRCurveMetric.compute()}\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator),allMetrics,TP_train,TN_train,FP_train,FN_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib-ttQW1rQOR"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.classification import PrecisionRecallCurve\n",
        "\n",
        "#from torchmetrics import AUC\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "# initialize metric\n",
        "\n",
        "def train3(model, iterator, optimizer, criterion):\n",
        "    #aucMetric =0\n",
        "    F1Metric=torchmetrics.F1Score(task='binary',compute_on_step=True).cuda()\n",
        "\n",
        "    PrecMetric=torchmetrics.Precision(task='binary',compute_on_step=True).cuda()\n",
        "    RecallMetric=torchmetrics.Recall(task='binary',compute_on_step=True).cuda()\n",
        "    aucRCurveMetric=torchmetrics.AUROC(task='binary',compute_on_step=True).cuda()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_auc=0\n",
        "    TP_train,TN_train,FP_train,FN_train=0,0,0,0\n",
        "    model.train()\n",
        "    gamma = torch.tensor(1.0, dtype = torch.float32).cuda()\n",
        "    alpha=torch.tensor(0.9, dtype = torch.float32).cuda()\n",
        "    for idx, (label, text, offsets,param) in enumerate(iterator):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #print(batch)\n",
        "        #print(batch.data)\n",
        "\n",
        "        predictions=model(text.to(device),offsets.to(device),param.to(device).requires_grad()).squeeze(1)\n",
        "\n",
        "        predictionsigmoid=torch.sigmoid(predictions)\n",
        "        rounded_preds=torch.round(predictionsigmoid)\n",
        "        #if idx==0:\n",
        "        #  print('predictions',predictionsigmoid)\n",
        "\n",
        "        #print(rounded_preds)\n",
        "\n",
        "        #print(\"Batch labels  \"+ batch.label.int().cuda())\n",
        "        bce_loss = criterion(predictions, label.to(device))\n",
        "        loss= focal_loss(bce_loss,label.to(device),gamma,alpha)\n",
        "        #print(loss)\n",
        "\n",
        "        acc = binary_accuracy(rounded_preds, label.to(device))\n",
        "        #aucMetric.update(rounded_preds, label)\n",
        "        F1Metric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "        PrecMetric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "        RecallMetric.update(rounded_preds,label.type(torch.IntTensor).cuda())\n",
        "        aucRCurveMetric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "        for i in range(len(label)):\n",
        "          if label[i]==0 and rounded_preds[i]==0:\n",
        "            TN_train+=1\n",
        "           # print (TN_train)\n",
        "          elif label[i]==1 and rounded_preds[i]==1:\n",
        "            TP_train+=1\n",
        "          elif label[i]==1 and rounded_preds[i]==0:\n",
        "            FP_train+=1\n",
        "          elif label[i]==0 and rounded_preds[i]==1:\n",
        "            FN_train+=1\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer3.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    allMetrics={'AUC':0,'Precision':PrecMetric.compute(),'Recall':RecallMetric.compute(),\n",
        "                'F1':F1Metric.compute(),'AUCR':aucRCurveMetric.compute()}\n",
        "\n",
        "    #allMetrics={'AUC':aucMetric.compute(),'F1':F1Metric.compute(),'Precision':PrecMetric.compute(),\n",
        "    #            'Recall':RecallMetric.compute(),'AUCR':aucRCurveMetric.compute()}\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator),allMetrics,TP_train,TN_train,FP_train,FN_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktbOcmvAl-0W"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "\n",
        "    #aucMetric = AUC(compute_on_step=True,reorder=True)\n",
        "    F1Metric=torchmetrics.F1Score(task='binary',compute_on_step=True).cuda()\n",
        "\n",
        "    PrecMetric=torchmetrics.Precision(task='binary',compute_on_step=True).cuda()\n",
        "    RecallMetric=torchmetrics.Recall(task='binary',compute_on_step=True).cuda()\n",
        "    aucRCurveMetric=torchmetrics.AUROC(task='binary',compute_on_step=True).cuda()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_auc=0\n",
        "\n",
        "    gamma = torch.tensor(1.0, dtype = torch.float32).cuda()\n",
        "    alpha=torch.tensor(0.5, dtype = torch.float32).cuda()\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for idx, (label, text, offsets) in enumerate(iterator):\n",
        "\n",
        "\n",
        "            predictions = model(text,offsets).squeeze(1)\n",
        "\n",
        "\n",
        "            predictionsigmoid=torch.sigmoid(predictions)\n",
        "            rounded_preds=torch.round(predictionsigmoid)\n",
        "\n",
        "\n",
        "        #print(rounded_preds)\n",
        "\n",
        "        #print(\"Batch labels  \"+ batch.label.int().cuda())\n",
        "            bce_loss = criterion(predictions, label)\n",
        "            loss= focal_loss(bce_loss,label,gamma,alpha)\n",
        "        #print(loss)\n",
        "\n",
        "            acc = binary_accuracy(rounded_preds, label)\n",
        "            #aucMetric.update(rounded_preds, label)\n",
        "            F1Metric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "            PrecMetric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "            RecallMetric.update(rounded_preds,label.type(torch.IntTensor).cuda())\n",
        "            aucRCurveMetric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    allMetrics={'AUC':0,'Precision':PrecMetric.compute(),'Recall':RecallMetric.compute(),\n",
        "                'F1':F1Metric.compute(),'AUCR':aucRCurveMetric.compute()}\n",
        "\n",
        "    #allMetrics={'AUC':aucMetric.compute(),'F1':F1Metric.compute(),'Precision':PrecMetric.compute(),\n",
        "    #            'Recall':RecallMetric.compute(),'AUCR':aucRCurveMetric.compute()}\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator),allMetrics,TP_train,TN_train,FP_train,FN_train\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlOwudo2rhqZ"
      },
      "outputs": [],
      "source": [
        "def evaluate3(model, iterator, criterion):\n",
        "\n",
        "\n",
        "    #aucMetric = 0\n",
        "    F1Metric=torchmetrics.F1Score(task='binary',compute_on_step=True).cuda()\n",
        "\n",
        "    PrecMetric=torchmetrics.Precision(task='binary',compute_on_step=True).cuda()\n",
        "    RecallMetric=torchmetrics.Recall(task='binary',compute_on_step=True).cuda()\n",
        "    aucRCurveMetric=torchmetrics.AUROC(task='binary',compute_on_step=True).cuda()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_auc=0\n",
        "    TP_train,TN_train,FP_train,FN_train=0,0,0,0\n",
        "    gamma = torch.tensor(1.0, dtype = torch.float32).cuda()\n",
        "    alpha=torch.tensor(0.5, dtype = torch.float32).cuda()\n",
        "    model3.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for idx, (label, text, offsets, param) in enumerate(iterator):\n",
        "\n",
        "\n",
        "            predictions = model3(text.to(device),offsets.to(device),param.to(device)).squeeze(1)\n",
        "\n",
        "\n",
        "            predictionsigmoid=torch.sigmoid(predictions)\n",
        "            rounded_preds=torch.round(predictionsigmoid)\n",
        "\n",
        "\n",
        "        #print(rounded_preds)\n",
        "\n",
        "        #print(\"Batch labels  \"+ batch.label.int().cuda())\n",
        "            bce_loss = criterion(predictions, label.to(device))\n",
        "            loss= focal_loss(bce_loss,label.to(device),gamma,alpha)\n",
        "        #print(loss)\n",
        "\n",
        "            acc = binary_accuracy(rounded_preds, label.to(device))\n",
        "            #aucMetric.update(rounded_preds, label)\n",
        "            F1Metric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "            PrecMetric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "            RecallMetric.update(rounded_preds,label.type(torch.IntTensor).cuda())\n",
        "            aucRCurveMetric.update(rounded_preds, label.type(torch.IntTensor).cuda())\n",
        "            for i in range(len(label)):\n",
        "                 if label[i]==0 and rounded_preds[i]==0:\n",
        "                      TN_train+=1\n",
        "           # print (TN_train)\n",
        "                 elif label[i]==1 and rounded_preds[i]==1:\n",
        "                      TP_train+=1\n",
        "                 elif label[i]==1 and rounded_preds[i]==0:\n",
        "                      FP_train+=1\n",
        "                 elif label[i]==0 and rounded_preds[i]==1:\n",
        "                      FN_train+=1\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    allMetrics={'AUC':0,'Precision':PrecMetric.compute(),'Recall':RecallMetric.compute(),\n",
        "                'F1':F1Metric.compute(),'AUCR':aucRCurveMetric.compute()}\n",
        "\n",
        "    #allMetrics={'AUC':aucMetric.compute(),'F1':F1Metric.compute(),'Precision':PrecMetric.compute(),\n",
        "    #            'Recall':RecallMetric.compute(),'AUCR':aucRCurveMetric.compute()}\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator),allMetrics,TP_train,TN_train,FP_train,FN_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HaxUmt-z10d",
        "outputId": "6a8269e5-9890-4fb3-decb-ae462637f543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 4.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbQISE9nzPyZ"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import xlsxwriter\n",
        "from xlrd import open_workbook\n",
        "import xlwt\n",
        "import os.path\n",
        "filename=datetime.now().strftime(\"%d-%b-%Y\")+\".xlsx\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS-3ZHGR3FQI"
      },
      "outputs": [],
      "source": [
        "os.environ['WANDB_CONSOLE'] = 'off'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "f2KtpFuRsHS7",
        "outputId": "e1c09d91-65e2-4c64-c371-b3ce4268ff3e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 56m 35s\n",
            "\tTrain Loss: 0.010 | Train Acc: 93.49 | All Metrics:{'AUC': 0, 'Precision': tensor(0., device='cuda:0'), 'Recall': tensor(0., device='cuda:0'), 'F1': tensor(0., device='cuda:0'), 'AUCR': tensor(0.5000, device='cuda:0')} | TP:0 | TN: 824383\n",
            "\t Val. Loss: 0.028 |  Val. Acc: 93.50 | Val All Metrics:{'AUC': 0, 'Precision': tensor(0., device='cuda:0'), 'Recall': tensor(0., device='cuda:0'), 'F1': tensor(0., device='cuda:0'), 'AUCR': tensor(0.5000, device='cuda:0')}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [1:11:47<10:46:06, 4307.44s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.028 | Test Acc: 93.43 | Test All Metrics:{'AUC': 0, 'Precision': tensor(0., device='cuda:0'), 'Recall': tensor(0., device='cuda:0'), 'F1': tensor(0., device='cuda:0'), 'AUCR': tensor(0.5000, device='cuda:0')}\n",
            "Epoch: 02 | Epoch Time: 60m 55s\n",
            "\tTrain Loss: 0.013 | Train Acc: 92.86 | All Metrics:{'AUC': 0, 'Precision': tensor(0.0710, device='cuda:0'), 'Recall': tensor(0.0082, device='cuda:0'), 'F1': tensor(0.0148, device='cuda:0'), 'AUCR': tensor(0.5004, device='cuda:0')} | TP:472 | TN: 818272\n",
            "\t Val. Loss: 0.043 |  Val. Acc: 93.46 | Val All Metrics:{'AUC': 0, 'Precision': tensor(0.0710, device='cuda:0'), 'Recall': tensor(0.0082, device='cuda:0'), 'F1': tensor(0.0148, device='cuda:0'), 'AUCR': tensor(0.5004, device='cuda:0')}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [2:27:45<9:54:01, 4455.13s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.028 | Test Acc: 93.44 | Test All Metrics:{'AUC': 0, 'Precision': tensor(0.0710, device='cuda:0'), 'Recall': tensor(0.0082, device='cuda:0'), 'F1': tensor(0.0148, device='cuda:0'), 'AUCR': tensor(0.5004, device='cuda:0')}\n",
            "Epoch: 03 | Epoch Time: 60m 28s\n",
            "\tTrain Loss: 0.016 | Train Acc: 91.91 | All Metrics:{'AUC': 0, 'Precision': tensor(0.0662, device='cuda:0'), 'Recall': tensor(0.0188, device='cuda:0'), 'F1': tensor(0.0292, device='cuda:0'), 'AUCR': tensor(0.5002, device='cuda:0')} | TP:1074 | TN: 809289\n",
            "\t Val. Loss: 0.055 |  Val. Acc: 93.46 | Val All Metrics:{'AUC': 0, 'Precision': tensor(0.0662, device='cuda:0'), 'Recall': tensor(0.0188, device='cuda:0'), 'F1': tensor(0.0292, device='cuda:0'), 'AUCR': tensor(0.5002, device='cuda:0')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [3:28:51<13:55:24, 6265.53s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-5b6dc3f853f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} | Val All Metrics:{train_allMetrics}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathModel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d-%b-%Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'tut1-model3.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_allMetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_TP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_TN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_FP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_FN\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestIter3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f} | Test All Metrics:{train_allMetrics}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-6eaec2f7ea1a>\u001b[0m in \u001b[0;36mevaluate3\u001b[0;34m(model, iterator, criterion)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "sheetName=datetime.now().strftime(\"%H-%M-%S\")\n",
        "workbook = xlsxwriter.Workbook(sheetName)\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "dfData=pd.DataFrame()\n",
        "\n",
        "Epoch=[]\n",
        "listDfData=[]\n",
        "train_lossList,valid_lossList,test_lossList=[],[],[]\n",
        "train_accList,valid_accList,test_accList=[],[],[]\n",
        "train_aucList,valid_aucList,test_aucList=[],[],[]\n",
        "train_auCuList,valid_auCuList,test_auCuList=[],[],[]\n",
        "train_F1List,valid_F1List,test_F1List=[],[],[]\n",
        "train_PreList,valid_PreList,test_PreList=[],[],[]\n",
        "train_RecallList,valid_RecallList,test_RecallList=[],[],[]\n",
        "train_FPList,valid_FPList,test_FPList=[],[],[]\n",
        "train_TPList,valid_TPList,test_TPList=[],[],[]\n",
        "train_FNList,valid_FNList,test_FNList=[],[],[]\n",
        "train_TNList,valid_TNList,test_TNList=[],[],[]\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in tqdm(range(N_EPOCHS)):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc,train_allMetrics,train_TP,train_TN,train_FP,train_FN = train3(model3, trainIter3, optimizer, criterion)\n",
        "    valid_loss, valid_acc,valid_allMetrics,valid_TP,valid_TN,valid_FP,valid_FN = evaluate3(model3, validIter3, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model3.state_dict(), pathModel+'/'+datetime.now().strftime(\"%d-%b-%Y\")+'tut1-model3.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} | All Metrics:{train_allMetrics} | TP:{train_TP} | TN: {train_TN}')\n",
        "\n",
        "    #print(f'\\tRecall:{TP_train / (FN_train + TP_train):.3f} | Precision:{TP_train / (FP_train + TP_train):.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} | Val All Metrics:{train_allMetrics}')\n",
        "    model3.load_state_dict(torch.load(pathModel+'/'+datetime.now().strftime(\"%d-%b-%Y\")+'tut1-model3.pt'))\n",
        "    test_loss, test_acc,test_allMetrics,test_TP,test_TN,test_FP,test_FN= evaluate3(model3, testIter3, criterion)\n",
        "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f} | Test All Metrics:{train_allMetrics}')\n",
        "\n",
        "    Epoch.append(epoch)\n",
        "    train_lossList.append(train_loss)\n",
        "    valid_lossList.append(valid_loss)\n",
        "    test_lossList.append(test_loss)\n",
        "    train_accList.append(train_acc*100)\n",
        "    valid_accList.append(valid_acc*100)\n",
        "    test_accList.append(test_acc*100)\n",
        "\n",
        "    # train_aucList.append(train_allMetrics['AUC'].cpu().numpy())\n",
        "    # valid_aucList.append(valid_allMetrics['AUC'].cpu().numpy())\n",
        "    # test_aucList.append(test_allMetrics['AUC'].cpu().numpy())\n",
        "    train_aucList.append(0)\n",
        "    valid_aucList.append(0)\n",
        "    test_aucList.append(0)\n",
        "    train_auCuList.append(train_allMetrics['AUCR'].cpu().numpy())\n",
        "    valid_auCuList.append(valid_allMetrics['AUCR'].cpu().numpy())\n",
        "    test_auCuList.append(test_allMetrics['AUCR'].cpu().numpy())\n",
        "    train_F1List.append(train_allMetrics['F1'].cpu().numpy())\n",
        "    valid_F1List.append(valid_allMetrics['F1'].cpu().numpy())\n",
        "    test_F1List.append(test_allMetrics['F1'].cpu().numpy())\n",
        "    train_PreList.append(train_allMetrics['Precision'].cpu().numpy())\n",
        "    valid_PreList.append(valid_allMetrics['Precision'].cpu().numpy())\n",
        "    test_PreList.append(test_allMetrics['Precision'].cpu().numpy())\n",
        "    train_RecallList.append(train_allMetrics['Recall'].cpu().numpy())\n",
        "    valid_RecallList.append(valid_allMetrics['Recall'].cpu().numpy())\n",
        "    test_RecallList.append(test_allMetrics['Recall'].cpu().numpy())\n",
        "    train_FPList.append(train_FP)\n",
        "    valid_FPList.append(valid_FP)\n",
        "    test_FPList.append(test_FP)\n",
        "    train_FNList.append(train_FN)\n",
        "    valid_FNList.append(valid_FN)\n",
        "    test_FNList.append(test_FN)\n",
        "    train_FPList.append(train_TP)\n",
        "    valid_FPList.append(valid_TP)\n",
        "    test_FPList.append(test_TP)\n",
        "    train_FNList.append(train_TN)\n",
        "    valid_FNList.append(valid_TN)\n",
        "    test_FNList.append(test_TN)\n",
        "\n",
        "dfData.insert(0, 'Epoch', Epoch)\n",
        "dfData.insert(1, 'train_loss_', train_lossList)\n",
        "dfData.insert(2, 'valid_loss_', valid_lossList)\n",
        "dfData.insert(3, 'test_loss_', test_lossList)\n",
        "dfData.insert(4, 'train_acc_', train_accList)\n",
        "dfData.insert(5, 'valid_acc_', valid_accList)\n",
        "dfData.insert(6, 'test_acc_', test_accList)\n",
        "dfData.insert(7, 'train_auc_', train_aucList)\n",
        "dfData.insert(8, 'valid_auc_', valid_aucList)\n",
        "dfData.insert(9, 'test_auc_', test_aucList)\n",
        "dfData.insert(10, 'train_AUCR_', train_auCuList)\n",
        "dfData.insert(11, 'valid_AUCR_', valid_auCuList)\n",
        "dfData.insert(12, 'test_AUCR_', test_F1List)\n",
        "dfData.insert(13, 'train_F1_', train_F1List)\n",
        "dfData.insert(14, 'valid_F1_', valid_F1List)\n",
        "dfData.insert(15, 'test_F1_', test_auCuList)\n",
        "dfData.insert(16, 'train_Precision_', train_PreList)\n",
        "dfData.insert(17, 'valid_Precision_', valid_PreList)\n",
        "dfData.insert(18, 'test_Precision_', test_PreList)\n",
        "dfData.insert(19, 'train_Recall_', train_RecallList)\n",
        "dfData.insert(20, 'valid_Recall_', valid_RecallList)\n",
        "dfData.insert(21, 'test_Recall_', test_RecallList)\n",
        "dfData.insert(22, 'train_FP_', train_FPList)\n",
        "dfData.insert(23, 'valid_FP_', valid_FPList)\n",
        "dfData.insert(24, 'test_FP_', test_FPList)\n",
        "dfData.insert(25, 'train_FN_', train_FNList)\n",
        "dfData.insert(26, 'valid_FN_', valid_FNList)\n",
        "dfData.insert(27, 'test_FN_', test_FNList)\n",
        "dfData.insert(28, 'train_TP_', train_TPList)\n",
        "dfData.insert(29, 'valid_TP_', valid_TPList)\n",
        "dfData.insert(30, 'test_TP_', test_TPList)\n",
        "dfData.insert(31, 'train_TN_', train_TNList)\n",
        "dfData.insert(32, 'valid_TN_', valid_TNList)\n",
        "dfData.insert(33, 'test_TN_', test_TNList)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGPa8MLvTEbw"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import xlsxwriter\n",
        "from xlrd import open_workbook\n",
        "import openpyxl\n",
        "import xlwt\n",
        "import os.path\n",
        "filename='Model3'+datetime.now().strftime(\"%d-%b-%Y\")+\".xlsx\"\n",
        "sheetName=datetime.now().strftime(\"%H-%M-%S\")\n",
        "workbook = xlsxwriter.Workbook(pathResutlts + filename)\n",
        "if os.path.isfile(pathResutlts+filename):\n",
        "    print('old file')\n",
        "    ExcelWorkbook = openpyxl.load_workbook(pathResutlts+filename)\n",
        "\n",
        "    # Generating the writer engine\n",
        "    writer = pd.ExcelWriter(pathResutlts+filename, engine = 'openpyxl')\n",
        "\n",
        "    # Assigning the workbook to the writer engine\n",
        "    writer.book = ExcelWorkbook\n",
        "\n",
        "    dfData.to_excel(writer, sheet_name = sheetName)\n",
        "\n",
        "    writer.save()\n",
        "else:\n",
        "\n",
        "    # saving the excel\n",
        "    dfData.to_excel(pathResutlts+filename,sheet_name=sheetName)\n",
        "    print('DataFrame is written to Excel File successfully.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snB8KNzCyvHL"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "writer = SummaryWriter('tensorboard/runs')\n",
        "N_EPOCHS = 3\n",
        "\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "Epoch=[]\n",
        "train_lossList,valid_lossList,test_lossList=[],[],[]\n",
        "train_accList,valid_accList,test_accList=[],[],[]\n",
        "train_aucList,valid_aucList,test_aucList=[],[],[]\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in tqdm(range(N_EPOCHS)):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc,train_allMetrics,TP_train,TN_train,FP_train,FN_train = train(model, trainIter, optimizer, criterion)\n",
        "    valid_loss, valid_acc,valid_allMetrics = evaluate(model, validIter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} | All Metrics:{train_allMetrics} | TP:{TP_train} | TN: {TN_train}')\n",
        "    print(TN_train)\n",
        "\n",
        "    print(f'\\tRecall:{TP_train / (FN_train + TP_train):.3f} | Precision:{TP_train / (FP_train + TP_train):.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} | Val All Metrics:{train_allMetrics}')\n",
        "    model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "    test_loss, test_acc,test_allMetrics= evaluate(model, testIter, criterion)\n",
        "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f} | Test All Metrics:{train_allMetrics}')\n",
        "    Epoch.append(epoch)\n",
        "    train_lossList.append(train_loss)\n",
        "    valid_lossList.append(valid_loss)\n",
        "    test_lossList.append(test_loss)\n",
        "    train_accList.append(train_acc*100)\n",
        "    valid_accList.append(valid_acc*100)\n",
        "    test_accList.append(test_acc*100)\n",
        "\n",
        "    train_aucList.append(train_allMetrics)\n",
        "    valid_aucList.append(valid_allMetrics)\n",
        "    test_aucList.append(test_allMetrics)\n",
        "    writer.add_scalar('Loss/train', round(train_loss,1), epoch)\n",
        "    writer.add_scalar('Loss/valid', round(valid_loss,1), epoch)\n",
        "    writer.add_scalar('Loss/test', round(test_loss,1), epoch)\n",
        "    writer.add_scalar('Accuracy/train', int(train_acc*100), epoch)\n",
        "    writer.add_scalar('Accuracy/valid',int(valid_acc*100), epoch)\n",
        "    writer.add_scalar('Accuracy/test', int(test_acc*100), epoch)\n",
        "    #writer.add_scalar('AUC/train', train_allMetrics, epoch)\n",
        "    #writer.add_scalar('AUC/valid',int(valid_auc*100), epoch)\n",
        "    #writer.add_scalar('AUC/test', int(test_auc*100), epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGjRSYtOsFH-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwU02ji1mJ8k"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "writer = SummaryWriter('tensorboard/runs')\n",
        "N_EPOCHS = 3\n",
        "\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "Epoch2=[]\n",
        "train_lossList2,valid_lossList2,test_lossList2=[],[],[]\n",
        "train_accList2,valid_accList2,test_accList2=[],[],[]\n",
        "train_aucList2,valid_aucList2,test_aucList2=[],[],[]\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in tqdm(range(N_EPOCHS)):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc,train_allMetrics,TP_train,TN_train,FP_train,FN_train = train(model, trainIter2, optimizer, criterion)\n",
        "    valid_loss, valid_acc,valid_allMetrics = evaluate(model, validIter2, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model2.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} | All Metrics:{train_allMetrics} | TP:{TP_train} | TN: {TN_train}')\n",
        "\n",
        "    print(f'\\tRecall:{TP_train / (FN_train + TP_train):.3f} | Precision:{TP_train / (FP_train + TP_train):.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} | Val All Metrics:{train_allMetrics}')\n",
        "    model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "    test_loss, test_acc,test_allMetrics= evaluate(model, testIter2, criterion)\n",
        "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f} | Test All Metrics:{train_allMetrics}')\n",
        "    Epoch2.append(epoch)\n",
        "    train_lossList2.append(train_loss)\n",
        "    valid_lossList2.append(valid_loss)\n",
        "    test_lossList2.append(test_loss)\n",
        "    train_accList2.append(train_acc*100)\n",
        "    valid_accList2.append(valid_acc*100)\n",
        "    test_accList2.append(test_acc*100)\n",
        "\n",
        "    train_aucList2.append(train_allMetrics)\n",
        "    valid_aucList2.append(valid_allMetrics)\n",
        "    test_aucList2.append(test_allMetrics)\n",
        "    writer.add_scalar('Loss/train', round(train_loss,1), epoch)\n",
        "    writer.add_scalar('Loss/valid', round(valid_loss,1), epoch)\n",
        "    writer.add_scalar('Loss/test', round(test_loss,1), epoch)\n",
        "    writer.add_scalar('Accuracy/train', int(train_acc*100), epoch)\n",
        "    writer.add_scalar('Accuracy/valid',int(valid_acc*100), epoch)\n",
        "    writer.add_scalar('Accuracy/test', int(test_acc*100), epoch)\n",
        "    #writer.add_scalar('AUC/train', train_allMetrics, epoch)\n",
        "    #writer.add_scalar('AUC/valid',int(valid_auc*100), epoch)\n",
        "    #writer.add_scalar('AUC/test', int(test_auc*100), epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y_1rits3aAE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47bA30UAmOfZ"
      },
      "outputs": [],
      "source": [
        "dfData=pd.DataFrame()\n",
        "dfData.insert(0, 'Epoch', Epoch)\n",
        "dfData.insert(1, 'train_loss', train_lossList)\n",
        "dfData.insert(2, 'valid_loss', valid_lossList)\n",
        "dfData.insert(3, 'test_loss', test_lossList)\n",
        "dfData.insert(4, 'train_acc', train_accList)\n",
        "dfData.insert(5, 'valid_acc', valid_accList)\n",
        "dfData.insert(6, 'test_acc', test_accList)\n",
        "dfData.insert(7, 'train_auc', train_aucList)\n",
        "dfData.insert(8, 'valid_auc', valid_aucList)\n",
        "dfData.insert(9, 'test_auc', test_aucList)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_wpJo_DmW1n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgSefC_arM_M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J09-U1FfmZqX"
      },
      "outputs": [],
      "source": [
        "\n",
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}